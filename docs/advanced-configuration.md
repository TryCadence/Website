---
title: Advanced Configuration
description: In-depth configuration guide for webhooks, AI validation, and custom patterns
---

# Advanced Configuration Guide

This guide covers advanced Cadence configuration including webhooks, AI validation, custom detection patterns, and performance tuning.

## Configuration File Locations

Cadence looks for configuration files in this order:

1. **Explicit:** `--config /path/to/cadence.yml`
2. **Current directory:** `./cadence.yml`
3. **Home directory:** `~/.cadence.yml`
4. **System:** `/etc/cadence/cadence.yml` (Unix/Linux)
5. **Program data:** `%APPDATA%\cadence\cadence.yml` (Windows)

## Complete Configuration Reference

```yaml
# Cadence Configuration File
# Comprehensive example with all available options

# Analysis Configuration
analysis:
  # Detection strategies to enable
  strategies:
    - velocity        # Track commit rate changes
    - size            # Detect unusually large commits
    - timing          # Analyze commit timing patterns
    - statistical     # Statistical analysis of metrics
    - merging         # Analyze merge patterns
    - dispersion      # Author dispersion analysis
    - ratio           # Metric ratio analysis
    - precision       # Precision measurement
  
  # Exclude patterns for files/directories
  exclude:
    - "*.lock"
    - "node_modules/"
    - ".git/"
    - "build/"
    - "dist/"
  
  # Include only these paths (if set, other paths ignored)
  include: []
  
  # Analysis range
  max_commits: 10000
  since: "2024-01-01T00:00:00Z"
  until: "2024-12-31T23:59:59Z"

# Thresholds for detection
thresholds:
  velocity:
    # Suspicious additions per commit
    suspicious_additions: 1000
    # Suspicious deletions per commit
    suspicious_deletions: 500
    # Percentage change in commit rate
    rate_change_percentage: 150
    
  size:
    # Large file threshold
    large_file_size: 10000
    # Large commit threshold
    large_commit_size: 5000
  
  timing:
    # Unusual time gaps (in hours)
    time_gap_threshold: 24
    # Commits per day threshold
    commits_per_day: 50
  
  statistical:
    # Standard deviation multiplier
    std_dev_threshold: 2.0

# Git Repository Analysis
git:
  # Repository path or GitHub URL
  repository: "https://github.com/owner/repo"
  
  # Branch to analyze (optional)
  branch: "main"
  
  # Shallow clone depth (0 = full history)
  depth: 0
  
  # Follow submodules
  follow_submodules: true
  
  # Timeout in seconds
  timeout: 300
  
  # Temporary directory for clones
  temp_dir: "/tmp"
  
  # Keep temporary directory after analysis
  keep_temp: false

# Web Analysis Configuration
web:
  # Request timeout in seconds
  timeout: 30
  
  # Follow HTTP redirects
  follow_redirects: true
  
  # User agent string
  user_agent: "Mozilla/5.0 (compatible; Cadence/1.0)"
  
  # Maximum content size (bytes)
  max_content: 5242880  # 5MB
  
  # Additional headers
  headers:
    Accept: "text/html,application/xhtml+xml"
    Accept-Language: "en-US,en;q=0.9"

# AI Validation Configuration
ai:
  # Enable AI-based validation
  enabled: false
  
  # AI Provider (openai, anthropic, google)
  provider: "openai"
  
  # OpenAI Configuration
  openai:
    api_key: "${OPENAI_API_KEY}"
    model: "gpt-4o-mini"
    # Model options:
    # - gpt-4o-mini (fast, cheap)
    # - gpt-4o (slower, expensive, more accurate)
    # - gpt-4-turbo
    
    # System prompt for validation
    system_prompt: |
      You are an expert at detecting AI-generated content.
      Analyze the provided text and determine if it was generated by AI.
      Respond with a confidence score from 0 to 1.
    
    # Temperature for response (0-1)
    temperature: 0.2
    
    # Maximum tokens in response
    max_tokens: 500
    
    # Timeout in seconds
    timeout: 30
  
  # Anthropic Configuration
  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"
    model: "claude-3-haiku-20240307"
    system_prompt: |
      You are an expert at detecting AI-generated content.
      Analyze the provided text and determine if it was generated by AI.
  
  # Google Configuration
  google:
    api_key: "${GOOGLE_API_KEY}"
    model: "gemini-1.5-flash"
  
  # Cache AI responses (to reduce API calls)
  cache_responses: true
  cache_ttl: 86400  # 24 hours
  
  # Batch processing for efficiency
  batch_size: 10
  batch_delay: 1000  # milliseconds between batches

# Custom Detection Patterns
patterns:
  # Custom overused phrases
  custom_phrases:
    - "In today's world"
    - "More than ever"
    - "At the end of the day"
    - "It goes without saying"
    - "Needless to say"
    - "That being said"
    - "Last but not least"
    - "As a matter of fact"
  
  # Custom placeholder patterns (regex)
  custom_placeholders:
    - "\\bThere are \\w+ ways to\\b"
    - "\\bOne can see that\\b"
    - "\\bIt is important to note\\b"
  
  # Custom boilerplate text (exact match)
  custom_boilerplate:
    - "All rights reserved"
    - "Powered by"
    - "Disclaimer:"
  
  # Language-specific patterns
  language_patterns:
    en:  # English patterns
      formal_transitions:
        - "Furthermore"
        - "Moreover"
        - "In addition"
      perfect_constructions:
        - "As one can see"
        - "It is clear that"

# Webhook Configuration
webhook:
  # Enable webhooks
  enabled: false
  
  # Webhook server port
  port: 8080
  
  # TLS/SSL Configuration
  tls:
    enabled: false
    cert_file: "/path/to/cert.pem"
    key_file: "/path/to/key.pem"
  
  # Webhook endpoints
  endpoints:
    # Analysis complete
    - event: "analysis.complete"
      url: "https://example.com/webhook/analysis"
      method: "POST"
      timeout: 10
      # Retry configuration
      retry:
        max_attempts: 3
        backoff_multiplier: 2
        initial_delay: 1000  # milliseconds
      
      # Custom headers
      headers:
        Authorization: "Bearer ${WEBHOOK_TOKEN}"
        X-Custom-Header: "custom-value"
      
      # Filter which analyses trigger this webhook
      filter:
        min_score: 0.7
        strategies: ["velocity", "size"]
    
    # Analysis error
    - event: "analysis.error"
      url: "https://example.com/webhook/error"
      method: "POST"
      timeout: 10
    
    # Web analysis
    - event: "web.analysis"
      url: "https://example.com/webhook/web"
      method: "POST"
      timeout: 10

# Output Configuration
output:
  # Default output format (json, text, csv)
  format: "json"
  
  # Include additional metadata
  include_metadata: true
  
  # Pretty-print JSON output
  pretty_print: true
  
  # Include raw data in reports
  include_raw_data: false

# Logging Configuration
logging:
  # Log level (debug, info, warning, error)
  level: "info"
  
  # Log format (json, text)
  format: "text"
  
  # Log file path (omit for stdout)
  file: "/var/log/cadence/cadence.log"
  
  # Maximum log file size (bytes)
  max_size: 104857600  # 100MB
  
  # Maximum number of backups
  max_backups: 10
  
  # Log retention days
  max_age: 30
  
  # Components to log in detail
  debug_components:
    - "detector"
    - "git"
    - "web"

# Performance Configuration
performance:
  # Number of parallel analysis workers
  workers: 4
  
  # Maximum concurrent git operations
  max_git_operations: 2
  
  # Memory usage optimization
  memory:
    # Stream analysis data when possible
    streaming: true
    # Max rows in memory before chunking
    chunk_size: 10000
  
  # Caching
  cache:
    enabled: true
    type: "memory"  # memory, redis
    ttl: 3600  # seconds
    max_size: "1GB"
    
    # Redis configuration (if type: redis)
    redis:
      host: "localhost"
      port: 6379
      db: 0
      password: "${REDIS_PASSWORD}"

# Notification Configuration
notifications:
  # Email notifications
  email:
    enabled: false
    provider: "smtp"
    smtp:
      host: "smtp.example.com"
      port: 587
      username: "${EMAIL_USERNAME}"
      password: "${EMAIL_PASSWORD}"
      from: "cadence@example.com"
      use_tls: true
    recipients:
      - "admin@example.com"
  
  # Slack notifications
  slack:
    enabled: false
    webhook_url: "${SLACK_WEBHOOK_URL}"
    channel: "#security"
    mention_on_alert: true
    high_confidence_threshold: 0.8
  
  # PagerDuty integration
  pagerduty:
    enabled: false
    integration_key: "${PAGERDUTY_KEY}"
    severity: "critical"

# Database Configuration (for persistent storage)
database:
  # Database type (sqlite, postgresql, mysql)
  type: "sqlite"
  
  # SQLite configuration
  sqlite:
    path: "./cadence.db"
  
  # PostgreSQL configuration
  postgresql:
    host: "localhost"
    port: 5432
    database: "cadence"
    username: "${DB_USERNAME}"
    password: "${DB_PASSWORD}"
    ssl_mode: "require"
    max_connections: 20
  
  # Automated backups
  backups:
    enabled: true
    schedule: "0 2 * * *"  # Daily at 2 AM
    retention: 30  # days
    path: "./backups"

# Environment-specific Overrides
environments:
  development:
    ai:
      enabled: false
    logging:
      level: "debug"
    webhooks:
      enabled: false
  
  staging:
    ai:
      enabled: true
      openai:
        model: "gpt-4o-mini"
    logging:
      level: "info"
    webhooks:
      enabled: true
  
  production:
    ai:
      enabled: true
      openai:
        model: "gpt-4o"
    logging:
      level: "warning"
    webhooks:
      enabled: true
```

## Environment Variables

Override configuration with environment variables:

```bash
# AI Configuration
export CADENCE_AI_ENABLED=true
export CADENCE_AI_PROVIDER=openai
export CADENCE_AI_OPENAI_API_KEY=sk-...

# Webhook Configuration
export CADENCE_WEBHOOK_ENABLED=true
export CADENCE_WEBHOOK_PORT=8080

# Git Configuration
export CADENCE_GIT_TIMEOUT=600
export CADENCE_GIT_MAX_COMMITS=5000

# Logging
export CADENCE_LOGGING_LEVEL=debug

# Database
export CADENCE_DATABASE_TYPE=postgresql
export CADENCE_DATABASE_POSTGRESQL_HOST=db.example.com
```

## Webhook Integration

### Setting Up Webhooks

1. **Enable webhook server:**

```yaml
webhook:
  enabled: true
  port: 8080
  tls:
    enabled: true
    cert_file: "/etc/cadence/cert.pem"
    key_file: "/etc/cadence/key.pem"
```

2. **Configure endpoints:**

```yaml
webhook:
  endpoints:
    - event: "analysis.complete"
      url: "https://your-server.com/webhook"
      method: "POST"
      headers:
        Authorization: "Bearer YOUR_TOKEN"
```

3. **Start webhook server:**

```bash
cadence webhook --config cadence.yml
```

### Webhook Payload Format

Analysis complete event:

```json
{
  "event": "analysis.complete",
  "timestamp": "2024-01-15T10:30:00Z",
  "analysis_id": "abc123def456",
  "repository": "https://github.com/owner/repo",
  "results": {
    "total_score": 0.72,
    "confidence": 0.85,
    "suspicious_commits": 15,
    "strategies": {
      "velocity": {
        "score": 0.68,
        "flagged": true
      },
      "size": {
        "score": 0.75,
        "flagged": true
      }
    }
  }
}
```

## AI Validation Setup

### OpenAI Configuration

```bash
# Set API key
export OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxx

# Verify
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

```yaml
ai:
  enabled: true
  provider: "openai"
  openai:
    api_key: "${OPENAI_API_KEY}"
    model: "gpt-4o-mini"
    temperature: 0.2
    max_tokens: 500
```

### Anthropic Configuration

```bash
export ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxx
```

```yaml
ai:
  enabled: true
  provider: "anthropic"
  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"
    model: "claude-3-haiku-20240307"
```

## Custom Detection Patterns

### Adding Custom Phrases

```yaml
patterns:
  custom_phrases:
    - "Your custom phrase 1"
    - "Your custom phrase 2"
    - "Domain-specific jargon to flag"
```

### Adding Regex Patterns

```yaml
patterns:
  custom_placeholders:
    - "\\b(basically|essentially)\\b"  # Common AI filler
    - "\\d+\\s+(reason|way|step)s?\\b"  # Listicle patterns
    - "\\b(As mentioned|As stated|As noted)\\b"  # Repetitive transitions
```

## Performance Tuning

### For Large Repositories

```yaml
git:
  # Limit analysis scope
  max_commits: 1000
  depth: 100  # Shallow clone
  
performance:
  # Increase parallelism
  workers: 8
  max_git_operations: 4
  
  # Use memory efficiently
  memory:
    chunk_size: 50000
```

### For High-Traffic Webhooks

```yaml
performance:
  # Cache results
  cache:
    enabled: true
    ttl: 3600
    max_size: "2GB"

webhook:
  endpoints:
    - event: "analysis.complete"
      retry:
        max_attempts: 5
        backoff_multiplier: 2
```

## Security Configuration

### API Keys and Secrets

```bash
# Use environment variables
export OPENAI_API_KEY=sk-...
export WEBHOOK_TOKEN=secret-token
export DB_PASSWORD=db-password

# Load from file (with restricted permissions)
chmod 600 .env
export $(cat .env | xargs)

# Use secrets manager
# AWS Secrets Manager, HashiCorp Vault, etc.
```

### TLS/SSL Configuration

```yaml
webhook:
  tls:
    enabled: true
    cert_file: "/etc/cadence/cert.pem"
    key_file: "/etc/cadence/key.pem"
    # Use Let's Encrypt
    # certbot certonly --standalone -d cadence.example.com
```

### Database Connection Security

```yaml
database:
  postgresql:
    ssl_mode: "require"  # or verify-full
    # Connection pooling for security
    max_connections: 10
```

## Multi-Environment Setup

### Development Configuration

```yaml
# cadence.dev.yml
ai:
  enabled: false
logging:
  level: "debug"
webhooks:
  enabled: false
performance:
  cache:
    enabled: false
```

### Production Configuration

```yaml
# cadence.prod.yml
ai:
  enabled: true
  openai:
    model: "gpt-4o"
logging:
  level: "warning"
  file: "/var/log/cadence/cadence.log"
webhooks:
  enabled: true
performance:
  cache:
    enabled: true
    ttl: 86400
```

### Using Environment-Specific Configs

```bash
# Development
cadence analyze /repo --config cadence.dev.yml

# Production
cadence analyze /repo --config cadence.prod.yml

# Or use environment variable
export CADENCE_CONFIG_FILE=cadence.prod.yml
cadence analyze /repo
```

## Next Steps

- [Webhook Documentation](../api-reference) - Detailed webhook API reference
- [Troubleshooting Guide](../troubleshooting) - Resolve configuration issues
- [Quick Start](../quick-start) - Get started with basic configuration
